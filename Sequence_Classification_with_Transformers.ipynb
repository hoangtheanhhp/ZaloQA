{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence Classification with Transformers",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e91a71aa022549148f2ee85f4056a2f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0222323b39384c68bf558c2a829a72e1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8429752c37f249cd99c6280f8552e13e",
              "IPY_MODEL_834048e3e6c949d5ab81540418c85705"
            ]
          }
        },
        "0222323b39384c68bf558c2a829a72e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8429752c37f249cd99c6280f8552e13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_38e28fc75fd941f586a3faabcd422938",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2403e1a9413f4d53baa609a49034b1e9"
          }
        },
        "834048e3e6c949d5ab81540418c85705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2c656ef078974be6aea863e3293b209b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:46&lt;00:00, 13.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90a1798a78b84ab297c8bc98d3850ddd"
          }
        },
        "38e28fc75fd941f586a3faabcd422938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2403e1a9413f4d53baa609a49034b1e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c656ef078974be6aea863e3293b209b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90a1798a78b84ab297c8bc98d3850ddd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0154ce62c64c4b5d91780e41c427a8df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_51bd30d2830e4f458054fd7219458d8e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_afe87d8044214181b0fca120750c980f",
              "IPY_MODEL_fdc7efb391eb4d73997e1ae7cfdf5263"
            ]
          }
        },
        "51bd30d2830e4f458054fd7219458d8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afe87d8044214181b0fca120750c980f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_43fc72178f2345b498ff2605ed91ad06",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1083389348,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1083389348,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a86fdf4504a412ca6ba52e023b09b58"
          }
        },
        "fdc7efb391eb4d73997e1ae7cfdf5263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_870440f6606d4f18b0bbcd5eca1dfd08",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.08G/1.08G [00:44&lt;00:00, 24.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ab221933f9047f3a61f78287b646720"
          }
        },
        "43fc72178f2345b498ff2605ed91ad06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a86fdf4504a412ca6ba52e023b09b58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "870440f6606d4f18b0bbcd5eca1dfd08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ab221933f9047f3a61f78287b646720": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5b78d2372a244e7b001a0b8c229278f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0aa90c0c59a54afcafef9a3fb746b5d7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_24d07ec20a714f628d073836df317a67",
              "IPY_MODEL_91d1a2c2a08e4f91a82c7be8339e7399"
            ]
          }
        },
        "0aa90c0c59a54afcafef9a3fb746b5d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24d07ec20a714f628d073836df317a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6e0df7a24ee5447baad51c4651ad76c5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d27d064e7ac48a78d8e53fac749b6ba"
          }
        },
        "91d1a2c2a08e4f91a82c7be8339e7399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ca517339724f4d0c94d83c2a216a00d4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:01&lt;00:00, 819kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d7d272c8be9492582b00ffc38a49b44"
          }
        },
        "6e0df7a24ee5447baad51c4651ad76c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d27d064e7ac48a78d8e53fac749b6ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca517339724f4d0c94d83c2a216a00d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d7d272c8be9492582b00ffc38a49b44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoangtheanhhp/ZaloQA/blob/bert/Sequence_Classification_with_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipMamgbw6bjL",
        "colab_type": "text"
      },
      "source": [
        "# Sequence Classification with Transformers\n",
        "\n",
        "This colab notebook will guide you through using the Transformers library to obtain state-of-the-art results on the sequence classification task. It is attached to [the following tutorial](https://medium.com/@lysandrejik/using-tensorflow-2-for-state-of-the-art-natural-language-processing-102445cda54a).\n",
        "\n",
        "We will be using two different models as a means of comparison: Google's BERT and Facebook's RoBERTa. Both have the same architecture but have had different pre-training approached."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTUcBra3NSqC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "968f5f19-7ba1-470a-adca-62d61f7a4ae5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KAjNG_J7K-w",
        "colab_type": "text"
      },
      "source": [
        "## Installing required dependencies\n",
        "In order to import the TensorFlow modules, we must make sure that TF2 is installed in the environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMvKYmV48aHi",
        "colab_type": "code",
        "outputId": "0b99cd19-1326-4124-9112-e98f3d9ccf1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH6P00pLYbXH",
        "colab_type": "code",
        "outputId": "d1d997a4-383b-462d-f0f2-18d3111aafcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/b5/ac41e3e95205ebf53439e4dd087c58e9fd371fd8e3724f2b9b4cdb8282e5/transformers-2.10.0-py3-none-any.whl (660kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 2.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 8.5MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 19.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=4f1eddc66c0e31715f01d30a546478b21b2cf6e9b9687bbcf3e8f939a0943fe2\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b18ixKx1TJoE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "a0232ae5-3aaa-4640-e991-bd012879b662"
      },
      "source": [
        "!pip install vncorenlp"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vncorenlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/c2/96a60cf75421ecc740829fa920c617b3dd7fa6791e17554e7c6f3e7d7fca/vncorenlp-1.0.3.tar.gz (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vncorenlp) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (1.24.3)\n",
            "Building wheels for collected packages: vncorenlp\n",
            "  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-cp36-none-any.whl size=2645935 sha256=0d654619c12097235ad3bbd752058c48a3dc18cf98719cfe4c00040fd728f789\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/54/8b/043667de6091d06a381d7745f44174504a9a4a56ecc9380c54\n",
            "Successfully built vncorenlp\n",
            "Installing collected packages: vncorenlp\n",
            "Successfully installed vncorenlp-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gUTG54xK_nz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_PATH = \"/content/drive/My Drive/ZaloAI/phobert/model.bin\"\n",
        "CONFIG_PATH = \"/content/drive/My Drive/ZaloAI/phobert/config.json\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTIzE-Nj5yvf",
        "colab_type": "text"
      },
      "source": [
        "## Initializing the pre-trained models\n",
        "\n",
        "Let's initialize the models with pre-trained weights. The list of pre-trained weights is available in [the official documentation](https://huggingface.co/transformers/pretrained_models.html). Downloading the weights may take a bit of time, but it only needs to be done once!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aihC2QV6IXk",
        "colab_type": "code",
        "outputId": "a5355982-5d23-4eb5-81f0-db8140b35570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "e91a71aa022549148f2ee85f4056a2f9",
            "0222323b39384c68bf558c2a829a72e1",
            "8429752c37f249cd99c6280f8552e13e",
            "834048e3e6c949d5ab81540418c85705",
            "38e28fc75fd941f586a3faabcd422938",
            "2403e1a9413f4d53baa609a49034b1e9",
            "2c656ef078974be6aea863e3293b209b",
            "90a1798a78b84ab297c8bc98d3850ddd",
            "0154ce62c64c4b5d91780e41c427a8df",
            "51bd30d2830e4f458054fd7219458d8e",
            "afe87d8044214181b0fca120750c980f",
            "fdc7efb391eb4d73997e1ae7cfdf5263",
            "43fc72178f2345b498ff2605ed91ad06",
            "7a86fdf4504a412ca6ba52e023b09b58",
            "870440f6606d4f18b0bbcd5eca1dfd08",
            "6ab221933f9047f3a61f78287b646720",
            "a5b78d2372a244e7b001a0b8c229278f",
            "0aa90c0c59a54afcafef9a3fb746b5d7",
            "24d07ec20a714f628d073836df317a67",
            "91d1a2c2a08e4f91a82c7be8339e7399",
            "6e0df7a24ee5447baad51c4651ad76c5",
            "3d27d064e7ac48a78d8e53fac749b6ba",
            "ca517339724f4d0c94d83c2a216a00d4",
            "5d7d272c8be9492582b00ffc38a49b44"
          ]
        }
      },
      "source": [
        "from transformers import RobertaConfig, TFBertForSequenceClassification, BertTokenizer, RobertaForSequenceClassification, RobertaTokenizer\n",
        "\n",
        "bert_model = TFBertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "config = RobertaConfig.from_pretrained(CONFIG_PATH)\n",
        "roberta_model = RobertaForSequenceClassification.from_pretrained(MODEL_PATH, config=config)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e91a71aa022549148f2ee85f4056a2f9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0154ce62c64c4b5d91780e41c427a8df",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1083389348.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5b78d2372a244e7b001a0b8c229278f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGFXXgaVL4F-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a3289d97-6ea7-4251-8395-7dcb5eaf671d"
      },
      "source": [
        "# See more details at: https://github.com/vncorenlp/VnCoreNLP\n",
        "\n",
        "# Load rdrsegmenter from VnCoreNLP\n",
        "from vncorenlp import VnCoreNLP\n",
        "rdrsegmenter = VnCoreNLP(\"/content/drive/My Drive/ZaloAI/VnCoreNLP/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m') \n",
        "\n",
        "# Input \n",
        "text = \"Ông Nguyễn Khắc Chúc  đang làm việc tại Đại học Quốc gia Hà Nội. Bà Lan, vợ ông Chúc, cũng làm việc tại đây.\"\n",
        "\n",
        "# To perform word segmentation only\n",
        "word_segmented_text = rdrsegmenter.tokenize(text) \n",
        "print(word_segmented_text)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Ông', 'Nguyễn_Khắc_Chúc', 'đang', 'làm_việc', 'tại', 'Đại_học', 'Quốc_gia', 'Hà_Nội', '.'], ['Bà', 'Lan', ',', 'vợ', 'ông', 'Chúc', ',', 'cũng', 'làm_việc', 'tại', 'đây', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zXIt_LK9TWt",
        "colab_type": "text"
      },
      "source": [
        "### Tokenization\n",
        "\n",
        "BERT and RoBERTa are both Transformer models that have the same architecture. As such, they accept only a certain kind of inputs: vectors of integers, each value representing a token. Each string of text must first be converted to a list of indices to be fed to the model. The tokenizer takes care of that for us.\n",
        "\n",
        "BERT and RoBERTa may have the same architecture, but they differ in tokenization. BERT uses a sub-word tokenization, whereas RoBERTa uses the same tokenization than GPT-2: byte-level byte-pair-encoding. Let's see what this means:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZRFEqLc8DV2",
        "colab_type": "code",
        "outputId": "32ff6abb-5723-4486-f88c-640bdd5dbb87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "sequence = \"Ai là người sáng chế ra nỏ liên châu. Nỏ liên châu do Cao Lỗ sáng chế vào thời Thục Phán An Dương Vương\"\n",
        "\n",
        "bert_tokenized_sequence = bert_tokenizer.tokenize(sequence)\n",
        "\n",
        "\n",
        "print(\"BERT:\", bert_tokenized_sequence)\n",
        "# print(\"RoBERTa:\", roberta_tokenized_sequence)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BERT: ['Ai', 'là', 'người', 'sáng', 'chế', 'ra', 'n', '##ỏ', 'liên', 'châu', '.', 'N', '##ỏ', 'liên', 'châu', 'do', 'Cao', 'L', '##ỗ', 'sáng', 'chế', 'vào', 'thời', 'Th', '##ục', 'Ph', '##án', 'An', 'Dương', 'Vương']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W19ze-Fd_RqD",
        "colab_type": "text"
      },
      "source": [
        "**BERT Tokenizer**\n",
        "\n",
        "Here, the BERT tokenizer splits the string into multiple substrings. If the substrings are in its vocabulary, they will stay as is: this is the case for `array`,  `are` and  `cool`. However, if a resulting string is not in its vocabulary, it will be split again until every string is represented by its vocabulary. For example,  `Systolic` is split multiple times until every token is represented in the BERT vocabulary: it is split into four tokens.\n",
        "The BERT tokenizer is lacking when it comes to complex characters spread over multiple bytes, as can be seen with emojis. In the sequence used, an emoji of a whale was added. As the BERT tokenizer cannot interpret this emoji on a byte-level, it replaces it by the unknown token [UNK].\n",
        "\n",
        "**RoBERTa Tokenizer**\n",
        "\n",
        "On the other hand, the RoBERTa tokenizer has a slightly different approach. Here too, the string is split into multiple substrings, which are themselves split into multiple substrings until every substring can be represented by the vocabulary. However, the RoBERTa tokenizer has a **byte-level approach**. This tokenizer can represent every sequence as a combination of bytes, which makes it shine in the case of complex characters spread over multiple bytes, as with the whale emoji. Instead of using the unknown token, this tokenizer can correctly encode the whale emoji as the combination of multiple bytes. This tokenizer therefore does not require an unknown token, as it can handle every byte separately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5TVSZtxEl32",
        "colab_type": "text"
      },
      "source": [
        "## Getting State-of-the-Art results on sequence classification\n",
        "\n",
        "In order to get State-of-the-Art results on this task, we will fine-tune our models on a given dataset. Fine-tuning a model means that we will slightly train it on top of an already trained checkpoint. The learning rate will be very low, as having it to high would result in catastrophic forgetting -> the model would forget what it had learned until now semantically and syntaxically.\n",
        "\n",
        "We will follow the procedure detailed below:\n",
        "\n",
        "    1) Get the dataset from `tensorflow_datasets`\n",
        "\n",
        "    2) Pre-process this dataset so that it can be used by the model\n",
        "\n",
        "    3) Set-up a training loop using Keras' fit API; train the model on the training data\n",
        "\n",
        "    4) Evaluate the model on the testing data and compare to the actual results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ImFqNidSIk9",
        "colab_type": "text"
      },
      "source": [
        "### Getting the dataset\n",
        "\n",
        "We will be using the Microsoft Research Paraphrase Corpus (MRPC) dataset, which is a sequence classification dataset. We get the train and validation data from the `tensorflow_datasets` package. These values are in the form of `tf.data.Dataset`, which is perfect for our use-case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro-ROZtP-GoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ZQAProcessor():\n",
        "  \"\"\"Processor for the Zalo Quation Answering data set.\"\"\"\n",
        "\n",
        "  def _read_json(self, input_file, islabel=True):\n",
        "    \"\"\"Reads a tab separated value file.\"\"\"\n",
        "    print('read_json..........')\n",
        "    try:\n",
        "        with open(input_file, 'r', encoding=\"utf-8\") as file:\n",
        "            data = json.load(file)\n",
        "            return [[data_instance['question'],\n",
        "                      data_instance['text'],\n",
        "                      str(data_instance.get('label', False))]\n",
        "                    for data_instance in tqdm(data)]\n",
        "    except FileNotFoundError:\n",
        "        return []\n",
        "\n",
        "  def get_train_examples(self, data_dir):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    return self._create_examples(\n",
        "        self._read_json(os.path.join(data_dir, \"train.json\")), \"train\")\n",
        "\n",
        "  def get_test_examples(self, data_dir):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    return self._create_examples(\n",
        "        self._read_json(os.path.join(data_dir, \"test.json\")), \"test\")\n",
        "\n",
        "  def get_labels(self):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    return [\"False\", \"True\"]\n",
        "\n",
        "  def _create_examples(self, lines, set_type):\n",
        "    \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "    examples = []\n",
        "    for (i, line) in enumerate(lines):\n",
        "      guid = \"%s-%s\" % (set_type, i)\n",
        "      text_a = tokenization.convert_to_unicode(line[0])\n",
        "      text_b = tokenization.convert_to_unicode(line[1])\n",
        "      label = tokenization.convert_to_unicode(line[2])\n",
        "      examples.append({\n",
        "          'guid' : guid, \n",
        "          'text_a': text_a, \n",
        "          'text_b': text_b, \n",
        "          'label' : label})\n",
        "    return examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr07j8B2TiEF",
        "colab_type": "text"
      },
      "source": [
        "Let's output the value of the first item of the dataset to get an idea of the data we're dealing with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMip2J9Iuqoq",
        "colab_type": "text"
      },
      "source": [
        "## Encoding sequences\n",
        "\n",
        "In order to encode the sequence to be understandable by the model, two different methods can come in handy.\n",
        "\n",
        "### encode()\n",
        "\n",
        "`encode` is a high-level method that returns the encoded sequence with the special tokens and truncated to a maximum length if need be. Here we identify the special CLS and SEP tokens of RoBERTa and BERT, and explicit them in the encoded sequence as to understand the difference in tokenization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR9yka31ul3V",
        "colab_type": "code",
        "outputId": "c7403ec3-e3e6-4700-c31f-57edebe219de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "encoded_bert_sequence = bert_tokenizer.encode(seq0, seq1, add_special_tokens=True, max_length=128)\n",
        "encoded_roberta_sequence = roberta_tokenizer.encode(seq0, seq1, add_special_tokens=True, max_length=128)\n",
        "\n",
        "print(\"BERT tokenizer separator, cls token id:   \", bert_tokenizer.sep_token_id, bert_tokenizer.cls_token_id)\n",
        "print(\"RoBERTa tokenizer separator, cls token id:\", roberta_tokenizer.sep_token_id, roberta_tokenizer.cls_token_id)\n",
        "\n",
        "bert_special_tokens = [bert_tokenizer.sep_token_id, bert_tokenizer.cls_token_id]\n",
        "roberta_special_tokens = [roberta_tokenizer.sep_token_id, roberta_tokenizer.cls_token_id]\n",
        "\n",
        "def print_in_red(string):\n",
        "    print(\"\\033[91m\" + str(string) + \"\\033[0m\", end=' ')\n",
        "\n",
        "print(\"\\nBERT tokenized sequence\")\n",
        "output = [print_in_red(tok) if tok in bert_special_tokens else print(tok, end=' ') for tok in encoded_bert_sequence]\n",
        "\n",
        "print(\"\\n\\nRoBERTa tokenized sequence\")\n",
        "output = [print_in_red(tok) if tok in roberta_special_tokens else print(tok, end=' ') for tok in encoded_roberta_sequence]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BERT tokenizer separator, cls token id:    102 101\n",
            "RoBERTa tokenizer separator, cls token id: 2 0\n",
            "\n",
            "BERT tokenized sequence\n",
            "\u001b[91m101\u001b[0m 157 13292 2528 1144 1215 1103 16513 15125 11944 1271 1290 1898 1111 1317 1104 1157 2815 2982 117 2452 1106 1103 19585 2858 17762 117 1756 1419 119 \u001b[91m102\u001b[0m 157 13292 2528 1144 1215 1103 16513 15125 11944 1271 1290 1898 1111 1317 1104 1157 2815 2982 117 1122 1163 119 \u001b[91m102\u001b[0m \n",
            "\n",
            "RoBERTa tokenized sequence\n",
            "\u001b[91m0\u001b[0m 565 1452 876 34 341 5 29110 42057 766 187 8148 13 484 9 63 806 785 2156 309 7 5 21065 18402 2156 886 138 479 \u001b[91m2\u001b[0m \u001b[91m2\u001b[0m 565 1452 876 34 341 5 29110 42057 766 187 8148 13 484 9 63 806 785 2156 24 26 479 \u001b[91m2\u001b[0m "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_apacxCvZZ7",
        "colab_type": "text"
      },
      "source": [
        "### encode_plus()\n",
        "\n",
        "`encode_plus` is similar to `encode` but it returns additional information: the token type ids as well as several other features that we don't need to manage right now.\n",
        "\n",
        "The token type ids are used by some models in the case of sequence classification. It is a mask indicating to the model which sequence a token is from. \n",
        "\n",
        "For example, let's say we have two sequences A and B with tokens `[a0, a1, a2, a3]` and `[b0, b1, b2, b3, b4]` respectively.\n",
        "\n",
        "The BERT tokenizer would create a single sequence from those two lists of tokens that would look like the following:\n",
        "\n",
        "<pre>\n",
        "[tokens]         `[CLS] a0 a1 a2 a3 [SEP] b0 b1 b2 b3 b4 [SEP]`. \n",
        "[token type ids] `  0    0  0  0  0   0    1  1  1  1  1   1`\n",
        "</pre>\n",
        "\n",
        "Thanks to the token type ids, the model is aware of which token belongs to which sequence\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73XQoKaBb1GG",
        "colab_type": "text"
      },
      "source": [
        "We won't need to use encode_plus in this experiment as directly in the `Transformers` library exists a method to directly convert a dataset to features, and is agnostic to both the GLUE task and the specified tokenizer. This method makes use of `encode_plus` under the hood and is called `glue_convert_examples_to_features`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTi1PqEoX-Sq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import glue_convert_examples_to_features\n",
        "\n",
        "bert_train_dataset = glue_convert_examples_to_features(train_dataset, bert_tokenizer, 128, 'mrpc')\n",
        "bert_train_dataset = bert_train_dataset.shuffle(100).batch(32).repeat(2)\n",
        "\n",
        "bert_validation_dataset = glue_convert_examples_to_features(validation_dataset, bert_tokenizer, 128, 'mrpc')\n",
        "bert_validation_dataset = bert_validation_dataset.batch(64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AERtOk6LfUT",
        "colab_type": "text"
      },
      "source": [
        "The two BERT datasets are now ready to be used: the training dataset is shuffled and batch, while the validation dataset is only batched.\n",
        "\n",
        "RoBERTa requires a bit more of work as it does not use the `token_type_ids`, which we need to remove. We use the `tf.data.Dataset.map()` method for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbdrVn7BuFSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def token_type_ids_removal(example, label):\n",
        "    del example[\"token_type_ids\"]\n",
        "    return example, label\n",
        "\n",
        "roberta_train_dataset = glue_convert_examples_to_features(train_dataset, roberta_tokenizer, 128, 'mrpc')\n",
        "roberta_train_dataset = roberta_train_dataset.map(token_type_ids_removal)\n",
        "roberta_train_dataset = roberta_train_dataset.shuffle(100).batch(32).repeat(2)\n",
        "\n",
        "roberta_validation_dataset = glue_convert_examples_to_features(validation_dataset, roberta_tokenizer, 128, 'mrpc')\n",
        "roberta_validation_dataset = roberta_validation_dataset.map(token_type_ids_removal)\n",
        "roberta_validation_dataset = roberta_validation_dataset.batch(64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOFkCP7seqHw",
        "colab_type": "text"
      },
      "source": [
        "### Defining the hyper-parameters\n",
        "\n",
        "Before fine-tuning the model, we must define a few hyperparameters that will be used during the training such as the optimizer, the loss and the evaluation metric.\n",
        "\n",
        "As an optimizer we'll be using Adam, which was the optimizer used during those models' pre-training. As a loss we'll be using the sparse categorical cross-entropy, and the sparse categorical accuracy as the evaluation metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQup8yJ2eDHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "\n",
        "bert_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
        "roberta_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2reI1c2HqfIt",
        "colab_type": "text"
      },
      "source": [
        "### Training the model\n",
        "\n",
        "The beauty of tensorflow/keras lies here: using keras' fit method to fine-tune the model with a single line of code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Soy6ZW-mqp0r",
        "colab_type": "code",
        "outputId": "4516e1c5-6fda-49a6-8184-1005c442cfbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "print(\"Fine-tuning BERT on MRPC\")\n",
        "bert_history = bert_model.fit(train, epochs=5, validation_data=test)\n",
        "\n",
        "print(\"\\nFine-tuning RoBERTa on MRPC\")\n",
        "roberta_history = roberta_model.fit(train, epochs=5, validation_data=test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fine-tuning BERT on MRPC\n",
            "Epoch 1/3\n",
            "230/230 [==============================] - 376s 2s/step - loss: 0.4896 - accuracy: 0.7601 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "230/230 [==============================] - 346s 2s/step - loss: 0.1541 - accuracy: 0.9434 - val_loss: 0.5791 - val_accuracy: 0.8456\n",
            "Epoch 3/3\n",
            "230/230 [==============================] - 347s 2s/step - loss: 0.0567 - accuracy: 0.9804 - val_loss: 0.5465 - val_accuracy: 0.8505\n",
            "\n",
            "Fine-tuning RoBERTa on MRPC\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "230/230 [==============================] - 377s 2s/step - loss: 0.6363 - accuracy: 0.6728 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "230/230 [==============================] - 349s 2s/step - loss: 0.6362 - accuracy: 0.6745 - val_loss: 0.6281 - val_accuracy: 0.6838\n",
            "Epoch 3/3\n",
            "230/230 [==============================] - 348s 2s/step - loss: 0.6351 - accuracy: 0.6745 - val_loss: 0.6280 - val_accuracy: 0.6838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YljeshET-_7U",
        "colab_type": "text"
      },
      "source": [
        "### Keras's simplicity doesn't end here\n",
        "\n",
        "Evaluating a model is as simple as it is to train it - using the evaluate method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scT82c9arCRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Evaluating the BERT model\")\n",
        "bert_model.evaluate(test)\n",
        "\n",
        "print(\"Evaluating the RoBERTa model\")\n",
        "roberta_model.evaluate(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj55Uq77tQ6J",
        "colab_type": "text"
      },
      "source": [
        "## Results\n",
        "\n",
        "The results we obtain for BERT are similar to the paper's original results, which were computed using the official GLUE evaluation server. The accuracy obtained for RoBERTa is slightly less than in the paper, which is probably due to the initialisation done: in the paper, the fine-tuning on the MRPC task was done from the MNLI checkpoint rather than from the base checkpoint."
      ]
    }
  ]
}